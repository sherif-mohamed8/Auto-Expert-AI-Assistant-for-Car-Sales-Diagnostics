import streamlit as st
import os
import pandas as pd
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent

# ==========================================
# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ÙˆØ§Ù„Ù…ÙØªØ§Ø­
# ==========================================
st.set_page_config(page_title="Auto-Expert AI", page_icon="ğŸš—", layout="wide")
st.title("ğŸš— Auto-Expert: Ù…Ø³Ø§Ø¹Ø¯Ùƒ Ø§Ù„Ø°ÙƒÙŠ Ù„Ù„Ø³ÙŠØ§Ø±Ø§Øª")
st.markdown("---")

# Ù…ÙØªØ§Ø­ Ø§Ù„Ù€ API (ØªØ£ÙƒØ¯ Ø¥Ù†Ù‡ Ø´ØºØ§Ù„)
api_key = "AIzaSyB6Jc9UUaYexpV6L-n0ZJKRz9TxVjskYls" 
os.environ["GOOGLE_API_KEY"] = api_key

# ==========================================
# 2. ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ù…ÙŠÙƒØ§Ù†ÙŠÙƒÙŠ (Mechanic Brain)
# ==========================================
@st.cache_resource 
def load_mechanic():
    print("ğŸ”§ Loading Mechanic Database...")
    embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
    if os.path.exists("faiss_index_mechanic"):
        vectorstore = FAISS.load_local(
            "faiss_index_mechanic", 
            embeddings, 
            allow_dangerous_deserialization=True
        )
        return vectorstore
    return None

def get_mechanic_response(query):
    vectorstore = load_mechanic()
    if not vectorstore:
        return "âŒ Error: Mechanic Database (FAISS) not found."
    
    # Ø§Ù„Ø¨Ø­Ø«
    docs = vectorstore.similarity_search(query, k=3)
    context = "\n".join([d.page_content for d in docs])
    
    # Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„
    llm = ChatGoogleGenerativeAI(model="models/gemini-2.5-flash", temperature=0.3)
    
    prompt = f"""
    Role: Expert Egyptian Mechanic.
    Context: {context}
    User Complaint: {query}
    Task: Explain cause and give 3 solution steps in Egyptian Arabic.
    """
    try:
        return llm.invoke(prompt).content
    except Exception as e:
        return f"âš ï¸ Mechanic Error: {str(e)}"

# ==========================================
# 3. ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª (Sales Agent)
# ==========================================
@st.cache_resource
def load_sales_agent():
    print("ğŸ’° Loading Sales Agent...")
    if os.path.exists("data/cleaned_car_data.csv"):
        df = pd.read_csv("data/cleaned_car_data.csv")
        llm = ChatGoogleGenerativeAI(model="models/gemini-2.5-flash", temperature=0)
        return create_pandas_dataframe_agent(
            llm, df, verbose=True, allow_dangerous_code=True,
            agent_executor_kwargs={"handle_parsing_errors": True}
        )
    return None

def get_sales_response(query):
    agent = load_sales_agent()
    if not agent:
        return "âŒ Error: Car CSV Data not found."
    
    prompt = f"Query: {query}. Answer in Egyptian Arabic. Format prices clearly."
    try:
        return agent.invoke(prompt)['output']
    except Exception as e:
        return f"âš ï¸ Sales Error: {str(e)}"

# ==========================================
# 4. Ø§Ù„Ù…Ø§ÙŠØ³ØªØ±Ùˆ (Router) ÙˆØ§Ù„ÙˆØ§Ø¬Ù‡Ø©
# ==========================================

# Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø´Ø§Øª
if "messages" not in st.session_state:
    st.session_state.messages = []

# Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ø§Ù„Ø³Ø¤Ø§Ù„
if prompt := st.chat_input("Ø§ÙƒØªØ¨ Ù…Ø´ÙƒÙ„ØªÙƒ Ø£Ùˆ Ø§Ø³ØªÙØ³Ø§Ø±Ùƒ Ù‡Ù†Ø§..."):
    # Ø¹Ø±Ø¶ Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙˆØ§Ù„Ø±Ø¯
    with st.chat_message("assistant"):
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªÙÙƒÙŠØ±... ğŸ§ "):
            
            router_llm = ChatGoogleGenerativeAI(model="models/gemini-2.5-flash", temperature=0)
            router_prompt = f"Classify: SALES (price/buy/sell) or MECHANIC (repair/issue). Query: {prompt}. Output 1 word."
            
            try:
                intent = router_llm.invoke(router_prompt).content.strip().upper()
            except:
                intent = "MECHANIC" 
            
            # Ø§Ù„ØªÙˆØ¬ÙŠÙ‡
            if intent == "SALES":
                response = get_sales_response(prompt)
                st.caption("ğŸ’° (Sales Agent)")
            else:
                response = get_mechanic_response(prompt)
                st.caption("ğŸ”§ (Mechanic Agent)")
            
            st.markdown(response)
            
    # Ø­ÙØ¸ Ø§Ù„Ø±Ø¯
    st.session_state.messages.append({"role": "assistant", "content": response})