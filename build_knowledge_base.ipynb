{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66bd3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\vs code college\\Final project NLP\\Auto_Expert\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\vs code college\\Final project NLP\\Auto_Expert\\venv\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\vs code college\\Final project NLP\\Auto_Expert\\venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "âœ… sentence_transformers is installed (Version: 5.2.0)\n",
      "ğŸš€ Starting the Mechanic Brain Initialization (Guaranteed Mode)...\n",
      "ğŸ“„ Loading PDF: data/2012 Hyundai Elantra Workshop Manual.pdf...\n",
      "âœ… Loaded 846 pages.\n",
      "âœ‚ï¸ Total chunks to process: 1133\n",
      "ğŸ’¾ Downloading Local Embedding Model (all-MiniLM-L6-v2)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andalus\\AppData\\Local\\Temp\\ipykernel_8728\\197783241.py:44: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
      "c:\\vs code college\\Final project NLP\\Auto_Expert\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Andalus\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš™ï¸ Embedding documents locally (This uses your CPU, please wait)...\n",
      "ğŸ‰ DONE! The Mechanic Brain is ready and saved locally.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# --- Ø¨Ù„ÙˆÙƒ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª (Validation) ---\n",
    "try:\n",
    "    import sentence_transformers\n",
    "    print(f\"âœ… sentence_transformers is installed (Version: {sentence_transformers.__version__})\")\n",
    "except ImportError:\n",
    "    print(\"âŒ Critical Error: The library is STILL not found.\")\n",
    "    print(\"Please run Step 1 again and make sure to RESTART the kernel.\")\n",
    "    sys.exit() # ÙˆÙ‚Ù Ø§Ù„ÙƒÙˆØ¯ ÙÙˆØ±Ø§Ù‹\n",
    "\n",
    "\n",
    "\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings \n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "print(\"ğŸš€ Starting the Mechanic Brain Initialization (Guaranteed Mode)...\")\n",
    "\n",
    "pdf_path = \"data/2012 Hyundai Elantra Workshop Manual.pdf\"\n",
    "\n",
    "if not os.path.exists(pdf_path):\n",
    "    print(f\"âŒ Error: File not found at {pdf_path}\")\n",
    "else:\n",
    "    try:\n",
    "        # 1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù\n",
    "        print(f\"ğŸ“„ Loading PDF: {pdf_path}...\")\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        docs = loader.load()\n",
    "        print(f\"âœ… Loaded {len(docs)} pages.\")\n",
    "\n",
    "        # 2. ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù…Ù„Ù\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "        splits = text_splitter.split_documents(docs)\n",
    "        print(f\"âœ‚ï¸ Total chunks to process: {len(splits)}\")\n",
    "\n",
    "        # 3. Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ù…Ø­Ù„ÙŠØ§Ù‹)\n",
    "        print(\"ğŸ’¾ Downloading Local Embedding Model (all-MiniLM-L6-v2)...\")\n",
    "        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„\n",
    "        embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "        \n",
    "        print(\"âš™ï¸ Embedding documents locally (This uses your CPU, please wait)...\")\n",
    "        vectorstore = FAISS.from_documents(splits, embeddings)\n",
    "\n",
    "        # 4. Ø­ÙØ¸ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
    "        vectorstore.save_local(\"faiss_index_mechanic\")\n",
    "        print(\"ğŸ‰ DONE! The Mechanic Brain is ready and saved locally.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1567aa8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\vs code college\\Final project NLP\\Auto_Expert\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\vs code college\\Final project NLP\\Auto_Expert\\venv\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\vs code college\\Final project NLP\\Auto_Expert\\venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "ğŸš€ Starting the Mechanics Brain Fusion (Hyundai + Nissan)...\n",
      "ğŸ“„ Loading Hyundai Manual: data/2012 Hyundai Elantra Workshop Manual.pdf...\n",
      "   âœ… Hyundai: Loaded 846 pages.\n",
      "ğŸ“‚ Loading Nissan Manuals from folder: data/N16-pulsar-almera...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:14<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… Nissan: Loaded 2898 pages.\n",
      "\n",
      "ğŸ“š Total Pages Collected: 3744\n",
      "âœ‚ï¸ Splitting text into chunks...\n",
      "ğŸ§© Total Chunks created: 5694\n",
      "ğŸ’¾ Embedding and Saving to 'faiss_index_mechanic'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andalus\\AppData\\Local\\Temp\\ipykernel_1476\\2078463326.py:62: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ‰ MISSION ACCOMPLISHED! The Dual-Expert Brain (Hyundai & Nissan) is ready.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings \n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Ø¥Ø¬Ø¨Ø§Ø± Ø§Ù„Ù†Ø¸Ø§Ù… Ø¹Ù„Ù‰ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙƒÙˆØ¨Ø±ÙŠ (Ù„Ø­Ù„ Ù…Ø´Ø§ÙƒÙ„ Keras)\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
    "\n",
    "print(\"ğŸš€ Starting the Mechanics Brain Fusion (Hyundai + Nissan)...\")\n",
    "\n",
    "# 1. ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª\n",
    "hyundai_path = \"data/2012 Hyundai Elantra Workshop Manual.pdf\"\n",
    "nissan_folder = \"data/N16-pulsar-almera\"\n",
    "\n",
    "all_docs = []\n",
    "\n",
    "# --- ØªØ­Ù…ÙŠÙ„ Ù‡ÙŠÙˆÙ†Ø¯Ø§ÙŠ ---\n",
    "if os.path.exists(hyundai_path):\n",
    "    print(f\"ğŸ“„ Loading Hyundai Manual: {hyundai_path}...\")\n",
    "    try:\n",
    "        loader_h = PyPDFLoader(hyundai_path)\n",
    "        docs_h = loader_h.load()\n",
    "        print(f\"   âœ… Hyundai: Loaded {len(docs_h)} pages.\")\n",
    "        all_docs.extend(docs_h)\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ Error loading Hyundai: {e}\")\n",
    "else:\n",
    "    print(f\"âš ï¸ Warning: Hyundai file not found at {hyundai_path}\")\n",
    "\n",
    "# --- ØªØ­Ù…ÙŠÙ„ Ù†ÙŠØ³Ø§Ù† (ÙÙˆÙ„Ø¯Ø± ÙƒØ§Ù…Ù„) ---\n",
    "if os.path.exists(nissan_folder):\n",
    "    print(f\"ğŸ“‚ Loading Nissan Manuals from folder: {nissan_folder}...\")\n",
    "    try:\n",
    "        # glob=\"*.pdf\" Ù…Ø¹Ù†Ø§Ù‡ Ù‡Ø§Øª ÙƒÙ„ Ù…Ù„ÙØ§Øª Ø§Ù„Ù€ PDF Ø§Ù„Ù„ÙŠ Ø¬ÙˆÙ‡ Ø§Ù„ÙÙˆÙ„Ø¯Ø± Ø¯Ù‡\n",
    "        loader_n = DirectoryLoader(nissan_folder, glob=\"*.pdf\", loader_cls=PyPDFLoader, show_progress=True)\n",
    "        docs_n = loader_n.load()\n",
    "        print(f\"   âœ… Nissan: Loaded {len(docs_n)} pages.\")\n",
    "        all_docs.extend(docs_n)\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ Error loading Nissan folder: {e}\")\n",
    "else:\n",
    "    print(f\"âš ï¸ Warning: Nissan folder not found at {nissan_folder}\")\n",
    "\n",
    "# --- Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ---\n",
    "if not all_docs:\n",
    "    print(\"\\nâŒ Critical Error: No documents loaded! Please check your data folder.\")\n",
    "    sys.exit()\n",
    "\n",
    "print(f\"\\nğŸ“š Total Pages Collected: {len(all_docs)}\")\n",
    "\n",
    "# --- Ø§Ù„ØªÙ‚Ø³ÙŠÙ… (Chunking) ---\n",
    "print(\"âœ‚ï¸ Splitting text into chunks...\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(all_docs)\n",
    "print(f\"ğŸ§© Total Chunks created: {len(splits)}\")\n",
    "\n",
    "# --- Ø§Ù„ØªØ¶Ù…ÙŠÙ† ÙˆØ§Ù„Ø­ÙØ¸ (Embedding) ---\n",
    "print(\"ğŸ’¾ Embedding and Saving to 'faiss_index_mechanic'...\")\n",
    "try:\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "    \n",
    "    # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø© (Ù‡ÙŠØ§Ø®Ø¯ ÙˆÙ‚Øª Ø´ÙˆÙŠØ© Ø¹Ø´Ø§Ù† Ù†ÙŠØ³Ø§Ù† Ù…Ù„ÙØ§ØªÙ‡ ÙƒØªÙŠØ±)\n",
    "    vectorstore = FAISS.from_documents(splits, embeddings)\n",
    "    \n",
    "    # Ø­ÙØ¸ Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø©\n",
    "    vectorstore.save_local(\"faiss_index_mechanic\")\n",
    "    \n",
    "    print(\"\\nğŸ‰ MISSION ACCOMPLISHED! The Dual-Expert Brain (Hyundai & Nissan) is ready.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error during embedding: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e9d46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andalus\\AppData\\Local\\Temp\\ipykernel_1476\\106170728.py:2: FutureWarning: \n",
      "\n",
      "All support for the `google.generativeai` package has ended. It will no longer be receiving \n",
      "updates or bug fixes. Please switch to the `google.genai` package as soon as possible.\n",
      "See README for more details:\n",
      "\n",
      "https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n",
      "\n",
      "  import google.generativeai as genai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Checking available models for YOU...\n",
      "âœ… FOUND: models/gemini-2.5-flash\n",
      "âœ… FOUND: models/gemini-2.5-pro\n",
      "âœ… FOUND: models/gemini-2.0-flash-exp\n",
      "âœ… FOUND: models/gemini-2.0-flash\n",
      "âœ… FOUND: models/gemini-2.0-flash-001\n",
      "âœ… FOUND: models/gemini-2.0-flash-lite-001\n",
      "âœ… FOUND: models/gemini-2.0-flash-lite\n",
      "âœ… FOUND: models/gemini-2.0-flash-lite-preview-02-05\n",
      "âœ… FOUND: models/gemini-2.0-flash-lite-preview\n",
      "âœ… FOUND: models/gemini-exp-1206\n",
      "âœ… FOUND: models/gemini-2.5-flash-preview-tts\n",
      "âœ… FOUND: models/gemini-2.5-pro-preview-tts\n",
      "âœ… FOUND: models/gemma-3-1b-it\n",
      "âœ… FOUND: models/gemma-3-4b-it\n",
      "âœ… FOUND: models/gemma-3-12b-it\n",
      "âœ… FOUND: models/gemma-3-27b-it\n",
      "âœ… FOUND: models/gemma-3n-e4b-it\n",
      "âœ… FOUND: models/gemma-3n-e2b-it\n",
      "âœ… FOUND: models/gemini-flash-latest\n",
      "âœ… FOUND: models/gemini-flash-lite-latest\n",
      "âœ… FOUND: models/gemini-pro-latest\n",
      "âœ… FOUND: models/gemini-2.5-flash-lite\n",
      "âœ… FOUND: models/gemini-2.5-flash-image-preview\n",
      "âœ… FOUND: models/gemini-2.5-flash-image\n",
      "âœ… FOUND: models/gemini-2.5-flash-preview-09-2025\n",
      "âœ… FOUND: models/gemini-2.5-flash-lite-preview-09-2025\n",
      "âœ… FOUND: models/gemini-3-pro-preview\n",
      "âœ… FOUND: models/gemini-3-flash-preview\n",
      "âœ… FOUND: models/gemini-3-pro-image-preview\n",
      "âœ… FOUND: models/nano-banana-pro-preview\n",
      "âœ… FOUND: models/gemini-robotics-er-1.5-preview\n",
      "âœ… FOUND: models/gemini-2.5-computer-use-preview-10-2025\n",
      "âœ… FOUND: models/deep-research-pro-preview-12-2025\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Ø­Ø· Ù…ÙØªØ§Ø­Ùƒ Ù‡Ù†Ø§\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyAq9aJ6VK2CN5Riv-nekINxCG2PtpH1r_I\"\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "\n",
    "print(\"ğŸ” Checking available models for YOU...\")\n",
    "\n",
    "try:\n",
    "    for m in genai.list_models():\n",
    "        if 'generateContent' in m.supported_generation_methods:\n",
    "            print(f\"âœ… FOUND: {m.name}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
