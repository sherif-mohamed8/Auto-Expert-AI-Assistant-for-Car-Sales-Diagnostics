{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce9ee66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete. Libraries Imported.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
    "\n",
    "# -----------------------------------------------------\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyB6Jc9UUaYexpV6L-n0ZJKRz9TxVjskYls\"\n",
    "# -----------------------------------------------------\n",
    "\n",
    "print(\"Setup Complete. Libraries Imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3f63353e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Mechanic Brain...\n",
      "Mechanic Agent is Ready (Database + Dictionary Loaded).\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Mechanic Brain...\")\n",
    "\n",
    "try:\n",
    "    # 1. تحميل الـ Vector Database\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "    vectorstore = FAISS.load_local(\n",
    "        \"faiss_index_mechanic\", \n",
    "        embeddings, \n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "    \n",
    "    # 2. تحميل قاموس المصطلحات\n",
    "    with open(\"data/automotive_knowledge.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        knowledge_base = json.load(f)\n",
    "        \n",
    "    print(\"Mechanic Agent is Ready (Database + Dictionary Loaded).\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading Mechanic Brain: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cbd55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Sales Consultant...\n",
      "Sales Agent is Ready (Loaded 10530 cars).\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Sales Consultant...\")\n",
    "\n",
    "try:\n",
    "    # 1. قراءة الداتا النظيفة\n",
    "    df = pd.read_csv(\"data/cleaned_car_data.csv\")\n",
    "    \n",
    "    sales_llm = ChatGoogleGenerativeAI(model=\"models/gemini-2.5-flash\", temperature=0)\n",
    "    \n",
    "    # 3. إنشاء الوكيل\n",
    "    sales_agent = create_pandas_dataframe_agent(\n",
    "        sales_llm, \n",
    "        df, \n",
    "        verbose=False,\n",
    "        allow_dangerous_code=True,\n",
    "        agent_executor_kwargs={\"handle_parsing_errors\": True}\n",
    "    )\n",
    "    \n",
    "    print(f\"Sales Agent is Ready (Loaded {len(df)} cars).\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading Sales Agent: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a9f42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Router Logic Initialized.\n"
     ]
    }
   ],
   "source": [
    "# إعداد موديل التصنيف\n",
    "router_llm = ChatGoogleGenerativeAI(model=\"models/gemini-2.5-flash\", temperature=0)\n",
    "\n",
    "# 1. دالة تحديد النية (Sales vs Mechanic)\n",
    "def classify_intent(query):\n",
    "    prompt = f\"\"\"\n",
    "    Classify the user's intent based on the query.\n",
    "    \n",
    "    User Query: \"{query}\"\n",
    "    \n",
    "    Rules:\n",
    "    - If the user asks about car prices, buying, selling, models availability, or \"cheapest/expensive\" -> Return 'SALES'.\n",
    "    - If the user asks about a problem, noise, smoke, vibration, repair, mechanic, or parts -> Return 'MECHANIC'.\n",
    "    - If unclear -> Return 'MECHANIC' (Default).\n",
    "    \n",
    "    Output only one word: SALES or MECHANIC.\n",
    "    \"\"\"\n",
    "    response = router_llm.invoke(prompt)\n",
    "    return response.content.strip().upper()\n",
    "\n",
    "# 2. دالة تنفيذ الميكانيكي\n",
    "def run_mechanic(query):\n",
    "    # أ. ترجمة العامية باستخدام القاموس\n",
    "    search_q = query\n",
    "    technical_topic = \"General Issue\"\n",
    "    \n",
    "    if \"symptoms_map\" in knowledge_base:\n",
    "        for s in knowledge_base[\"symptoms_map\"]:\n",
    "            if any(k in query for k in s[\"keywords\"]):\n",
    "                search_q = s[\"search_query\"]\n",
    "                technical_topic = s[\"technical_term\"]\n",
    "                break\n",
    "    \n",
    "    # ب. البحث في الكتالوج\n",
    "    docs = vectorstore.similarity_search(search_q, k=3)\n",
    "    context = \"\\n\".join([d.page_content for d in docs])\n",
    "    \n",
    "    # ج. صياغة الرد\n",
    "    prompt = f\"\"\"\n",
    "    Role: Expert Egyptian Mechanic.\n",
    "    Context: {context}\n",
    "    User Complaint: {query} (Topic: {technical_topic})\n",
    "    \n",
    "    Answer in Egyptian Arabic. Provide 3 actionable steps.\n",
    "    \"\"\"\n",
    "    response = router_llm.invoke(prompt)\n",
    "    return response.content\n",
    "\n",
    "# 3. دالة تنفيذ المبيعات\n",
    "def run_sales(query):\n",
    "    prompt = f\"\"\"\n",
    "    User Query: {query}\n",
    "    Answer in Egyptian Arabic. Be helpful. Format prices clearly.\n",
    "    \"\"\"\n",
    "    response = sales_agent.invoke(prompt)\n",
    "    return response['output']\n",
    "\n",
    "print(\"Router Logic Initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6625b99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_expert_chat(user_input):\n",
    "    print(f\"\\n User: {user_input}\")\n",
    "    \n",
    "    intent = classify_intent(user_input)\n",
    "    print(f\" Maestro Decision: This is a [{intent}] task.\")\n",
    "    \n",
    "    # 2. التوجيه وتنفيذ المهمة\n",
    "    if intent == \"SALES\":\n",
    "        print(\"   -> Routing to Sales Agent...\")\n",
    "        response = run_sales(user_input)\n",
    "    else:\n",
    "        print(\"   -> Routing to Mechanic Agent...\")\n",
    "        response = run_mechanic(user_input)\n",
    "        \n",
    "    # 3. طباعة الرد النهائي\n",
    "    print(\"\\n Auto-Expert Answer:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(response)\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "61795bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " User: العربية بتنتش ومخنوقة\n",
      " Maestro Decision: This is a [MECHANIC] task.\n",
      "   -> Routing to Mechanic Agent...\n",
      "\n",
      " Auto-Expert Answer:\n",
      "--------------------------------------------------\n",
      "يا باشا، العربية لما بتنتش ومخنوقة كده، دي غالبًا بتكون مشكلة في الحريق بتاع البنزين في سلندر أو أكتر، يعني فيه \"Misfire\". متقلقش، احنا عندنا خطوات نمشي عليها عشان نعرف المشكلة فين بالظبط.\n",
      "\n",
      "إليك 3 خطوات أساسية هنعملها عشان نضيّق دايرة الشك ونوصل للعطل:\n",
      "\n",
      "1.  **اختبار الـ \"Power Balance\" (تحديد السلندر المشكلة):**\n",
      "    *   **لو عندنا جهاز CONSULT-II:** هنوصل الجهاز ونعمل اختبار \"POWER BALANCE\" في وضع \"ACTIVE TEST\". الجهاز هيوريك أي سلندر مش بيعمل هبوط لحظي في سرعة الموتور لما بنوقفه، وده معناه إن السلندر ده هو اللي مش شغال بكفاءة.\n",
      "    *   **لو مفيش CONSULT-II:** هنشغل العربية ونسيبها دايرة، وبعدين هنفصل فيشة كل رشاش (Injector harness connector) واحد ورا التاني. السلندر اللي هتفصل الفيشة بتاعته وميحصلش أي تغيير ملحوظ في صوت الموتور أو اهتزاز العربية، يبقى هو ده السلندر اللي فيه المشكلة الأساسية.\n",
      "\n",
      "2.  **فحص صوت الرشاشات (تأكيد عمل الرشاش):**\n",
      "    *   بعد ما نحدد السلندر اللي فيه المشكلة من الخطوة الأولى، هنيجي عند الرشاش بتاعه ونسمع صوته كويس والعربية دايرة على السلانسيه. الرشاش اللي شغال صح لازم يعمل صوت \"تكة\" (Clicking sound) مميزة.\n",
      "    *   **لو مفيش صوت تكة:** يبقى الرشاش ده مبيوصلوش كهرباء أو الرشاش نفسه تالف ومحتاج يتغير أو نفحص دائرته الكهربائية. (نرجع للدياجرام في EC-542).\n",
      "    *   **لو فيه صوت تكة:** يبقى الرشاش بيوصله كهرباء وبيفتح، بس ممكن يكون فيه مشكلة تانية فيه زي السدد أو التنقيط، ودي اللي هنفحصها في الخطوة الجاية.\n",
      "\n",
      "3.  **فحص تسريب الرشاشات وبخاخاتها (تأكيد جودة البخ):**\n",
      "    *   هنخلي العربية تبرد تمامًا عشان الأمان.\n",
      "    *   هنفك مجموعة الرشاشات من مكانها بس هنسيب خراطيم البنزين والرشاشات متصلة بمسطرة البنزين.\n",
      "    *   هنفصل فيش كل الرشاشات وكل موبينة (Ignition coil).\n",
      "    *   هنحط أطباق أو أوعية صغيرة تحت كل رشاش.\n",
      "    *   هندور مارش العربية حوالي 3 ثواني (من غير ما تشغلها طبعًا). المفروض إن مفيش نقطة بنزين تنزل من الرشاشات في الوقت ده.\n",
      "    *   **لو في رشاش بينقط بنزين:** يبقى الرشاش ده بايظ وبيسرب ومحتاج يتغير.\n",
      "    *   كمان في الخطوة دي، بنقدر نشوف شكل البخاخة بتاعة كل رشاش وهو بيبخ. لو في رشاش بيطلع بنزين على شكل \"خرطوم\" بدل ما يكون \"رذاذ\" (Spray pattern)، يبقى ده مسدود أو مش سليم ومحتاج تنظيف أو تغيير.\n",
      "\n",
      "بالخطوات دي، هنقدر نوصل للمشكلة الرئيسية إن شاء الله ونحلها!\n",
      "--------------------------------------------------\n",
      "\n",
      " User: معايا 2 مليون جنيه، ايه احسن عربية مرسيدس اجيبها؟\n",
      " Maestro Decision: This is a [SALES] task.\n",
      "   -> Routing to Sales Agent...\n",
      "\n",
      " Auto-Expert Answer:\n",
      "--------------------------------------------------\n",
      "يا فندم بأقل من 2 مليون جنيه، أنسب عربية مرسيدس ممكن تلاقيها هي:\n",
      "\n",
      "**Mercedes-Benz EQA 260 2025 استيراد حجز واستلام**\n",
      "سنة الصنع: 2025\n",
      "السعر: 1,958,522 جنيه مصري\n",
      "المسافة المقطوعة: 0 كم\n",
      "النوع: Electric\n",
      "المكان: New Cairo, Cairo•\n",
      "\n",
      "يارب تكون دي أنسب حاجة ليك!\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# سؤال ميكانيكا\n",
    "auto_expert_chat(\"العربية بتنتش ومخنوقة\")\n",
    "\n",
    "# سؤال مبيعات\n",
    "auto_expert_chat(\"معايا 2 مليون جنيه، ايه احسن عربية مرسيدس اجيبها؟\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "41cef89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " User: عايز اشتري احسن عربية في حدود مليون ونص جنيه وتكون معتمده ع انها تبقي واسعه ومريحة للعيلة\n",
      " Maestro Decision: This is a [SALES] task.\n",
      "   -> Routing to Sales Agent...\n"
     ]
    },
    {
     "ename": "ClientError",
     "evalue": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 46.919856701s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '46s'}]}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mClientError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mauto_expert_chat\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mعايز اشتري احسن عربية في حدود مليون ونص جنيه وتكون معتمده ع انها تبقي واسعه ومريحة للعيلة\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mauto_expert_chat\u001b[39m\u001b[34m(user_input)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m intent == \u001b[33m\"\u001b[39m\u001b[33mSALES\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     10\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m   -> Routing to Sales Agent...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     response = \u001b[43mrun_sales\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     13\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m   -> Routing to Mechanic Agent...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 55\u001b[39m, in \u001b[36mrun_sales\u001b[39m\u001b[34m(query)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_sales\u001b[39m(query):\n\u001b[32m     51\u001b[39m     prompt = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[33m    User Query: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[33m    Answer in Egyptian Arabic. Be helpful. Format prices clearly.\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[33m    \u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m     response = \u001b[43msales_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response[\u001b[33m'\u001b[39m\u001b[33moutput\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\vs code college\\Final project NLP\\Auto_Expert\\venv\\Lib\\site-packages\\langchain_classic\\chains\\base.py:167\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    165\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_inputs(inputs)\n\u001b[32m    166\u001b[39m     outputs = (\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    168\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    169\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call(inputs)\n\u001b[32m    170\u001b[39m     )\n\u001b[32m    172\u001b[39m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] = \u001b[38;5;28mself\u001b[39m.prep_outputs(\n\u001b[32m    173\u001b[39m         inputs,\n\u001b[32m    174\u001b[39m         outputs,\n\u001b[32m    175\u001b[39m         return_only_outputs,\n\u001b[32m    176\u001b[39m     )\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\vs code college\\Final project NLP\\Auto_Expert\\venv\\Lib\\site-packages\\langchain_classic\\agents\\agent.py:1590\u001b[39m, in \u001b[36mAgentExecutor._call\u001b[39m\u001b[34m(self, inputs, run_manager)\u001b[39m\n\u001b[32m   1588\u001b[39m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[32m   1589\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_continue(iterations, time_elapsed):\n\u001b[32m-> \u001b[39m\u001b[32m1590\u001b[39m     next_step_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1591\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1592\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1593\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1594\u001b[39m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1595\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1596\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1597\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[32m   1598\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._return(\n\u001b[32m   1599\u001b[39m             next_step_output,\n\u001b[32m   1600\u001b[39m             intermediate_steps,\n\u001b[32m   1601\u001b[39m             run_manager=run_manager,\n\u001b[32m   1602\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\vs code college\\Final project NLP\\Auto_Expert\\venv\\Lib\\site-packages\\langchain_classic\\agents\\agent.py:1290\u001b[39m, in \u001b[36mAgentExecutor._take_next_step\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[39m\n\u001b[32m   1281\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_take_next_step\u001b[39m(\n\u001b[32m   1282\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1283\u001b[39m     name_to_tool_map: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1287\u001b[39m     run_manager: CallbackManagerForChainRun | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1288\u001b[39m ) -> AgentFinish | \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[AgentAction, \u001b[38;5;28mstr\u001b[39m]]:\n\u001b[32m   1289\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._consume_next_step(\n\u001b[32m-> \u001b[39m\u001b[32m1290\u001b[39m         \u001b[38;5;28mlist\u001b[39m(\n\u001b[32m   1291\u001b[39m             \u001b[38;5;28mself\u001b[39m._iter_next_step(\n\u001b[32m   1292\u001b[39m                 name_to_tool_map,\n\u001b[32m   1293\u001b[39m                 color_mapping,\n\u001b[32m   1294\u001b[39m                 inputs,\n\u001b[32m   1295\u001b[39m                 intermediate_steps,\n\u001b[32m   1296\u001b[39m                 run_manager,\n\u001b[32m   1297\u001b[39m             ),\n\u001b[32m   1298\u001b[39m         ),\n\u001b[32m   1299\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\vs code college\\Final project NLP\\Auto_Expert\\venv\\Lib\\site-packages\\langchain_classic\\agents\\agent.py:1317\u001b[39m, in \u001b[36mAgentExecutor._iter_next_step\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[39m\n\u001b[32m   1314\u001b[39m     intermediate_steps = \u001b[38;5;28mself\u001b[39m._prepare_intermediate_steps(intermediate_steps)\n\u001b[32m   1316\u001b[39m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1317\u001b[39m     output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_action_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1318\u001b[39m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1319\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1320\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1321\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1322\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1323\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.handle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\vs code college\\Final project NLP\\Auto_Expert\\venv\\Lib\\site-packages\\langchain_classic\\agents\\agent.py:445\u001b[39m, in \u001b[36mRunnableAgent.plan\u001b[39m\u001b[34m(self, intermediate_steps, callbacks, **kwargs)\u001b[39m\n\u001b[32m    437\u001b[39m final_output: Any = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    438\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stream_runnable:\n\u001b[32m    439\u001b[39m     \u001b[38;5;66;03m# Use streaming to make sure that the underlying LLM is invoked in a\u001b[39;00m\n\u001b[32m    440\u001b[39m     \u001b[38;5;66;03m# streaming\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    443\u001b[39m     \u001b[38;5;66;03m# Because the response from the plan is not a generator, we need to\u001b[39;00m\n\u001b[32m    444\u001b[39m     \u001b[38;5;66;03m# accumulate the output into final output and return that.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m445\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrunnable\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    446\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfinal_output\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfinal_output\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\vs code college\\Final project NLP\\Auto_Expert\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3528\u001b[39m, in \u001b[36mRunnableSequence.stream\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3521\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   3522\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstream\u001b[39m(\n\u001b[32m   3523\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3526\u001b[39m     **kwargs: Any | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   3527\u001b[39m ) -> Iterator[Output]:\n\u001b[32m-> \u001b[39m\u001b[32m3528\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform(\u001b[38;5;28miter\u001b[39m([\u001b[38;5;28minput\u001b[39m]), config, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\vs code college\\Final project NLP\\Auto_Expert\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3514\u001b[39m, in \u001b[36mRunnableSequence.transform\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3507\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   3508\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtransform\u001b[39m(\n\u001b[32m   3509\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3512\u001b[39m     **kwargs: Any | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   3513\u001b[39m ) -> Iterator[Output]:\n\u001b[32m-> \u001b[39m\u001b[32m3514\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._transform_stream_with_config(\n\u001b[32m   3515\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   3516\u001b[39m         \u001b[38;5;28mself\u001b[39m._transform,\n\u001b[32m   3517\u001b[39m         patch_config(config, run_name=(config \u001b[38;5;129;01mor\u001b[39;00m {}).get(\u001b[33m\"\u001b[39m\u001b[33mrun_name\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.name),\n\u001b[32m   3518\u001b[39m         **kwargs,\n\u001b[32m   3519\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\vs code college\\Final project NLP\\Auto_Expert\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2324\u001b[39m, in \u001b[36mRunnable._transform_stream_with_config\u001b[39m\u001b[34m(self, inputs, transformer, config, run_type, **kwargs)\u001b[39m\n\u001b[32m   2322\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   2323\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2324\u001b[39m         chunk: Output = context.run(\u001b[38;5;28mnext\u001b[39m, iterator)\n\u001b[32m   2325\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[32m   2326\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m final_output_supported:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\vs code college\\Final project NLP\\Auto_Expert\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3480\u001b[39m, in \u001b[36mRunnableSequence._transform\u001b[39m\u001b[34m(self, inputs, run_manager, config, **kwargs)\u001b[39m\n\u001b[32m   3477\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3478\u001b[39m         final_pipeline = step.transform(final_pipeline, config)\n\u001b[32m-> \u001b[39m\u001b[32m3480\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m final_pipeline\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\vs code college\\Final project NLP\\Auto_Expert\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1542\u001b[39m, in \u001b[36mRunnable.transform\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   1539\u001b[39m final: Input\n\u001b[32m   1540\u001b[39m got_first_val = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1542\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43michunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# The default implementation of transform is to buffer input and\u001b[39;49;00m\n\u001b[32m   1544\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# then call stream.\u001b[39;49;00m\n\u001b[32m   1545\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# It'll attempt to gather all input into a single chunk using\u001b[39;49;00m\n\u001b[32m   1546\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# the `+` operator.\u001b[39;49;00m\n\u001b[32m   1547\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If the input is not addable, then we'll assume that we can\u001b[39;49;00m\n\u001b[32m   1548\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# only operate on the last chunk,\u001b[39;49;00m\n\u001b[32m   1549\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# and we'll iterate until we get to the last chunk.\u001b[39;49;00m\n\u001b[32m   1550\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgot_first_val\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1551\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfinal\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43michunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\vs code college\\Final project NLP\\Auto_Expert\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5773\u001b[39m, in \u001b[36mRunnableBindingBase.transform\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5766\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5767\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtransform\u001b[39m(\n\u001b[32m   5768\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5771\u001b[39m     **kwargs: Any,\n\u001b[32m   5772\u001b[39m ) -> Iterator[Output]:\n\u001b[32m-> \u001b[39m\u001b[32m5773\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bound.transform(\n\u001b[32m   5774\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   5775\u001b[39m         \u001b[38;5;28mself\u001b[39m._merge_configs(config),\n\u001b[32m   5776\u001b[39m         **{**\u001b[38;5;28mself\u001b[39m.kwargs, **kwargs},\n\u001b[32m   5777\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\vs code college\\Final project NLP\\Auto_Expert\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1560\u001b[39m, in \u001b[36mRunnable.transform\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m             final = ichunk\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m got_first_val:\n\u001b[32m-> \u001b[39m\u001b[32m1560\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stream(final, config, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\vs code college\\Final project NLP\\Auto_Expert\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:536\u001b[39m, in \u001b[36mBaseChatModel.stream\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    534\u001b[39m index = -\u001b[32m1\u001b[39m\n\u001b[32m    535\u001b[39m index_type = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m536\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m    538\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_id\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\vs code college\\Final project NLP\\Auto_Expert\\venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:3133\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._stream\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   3131\u001b[39m index = -\u001b[32m1\u001b[39m\n\u001b[32m   3132\u001b[39m index_type = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m3133\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3134\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3135\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_chat_result\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m_response_to_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3136\u001b[39m \u001b[43m            \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_usage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprev_usage_metadata\u001b[49m\n\u001b[32m   3137\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\vs code college\\Final project NLP\\Auto_Expert\\venv\\Lib\\site-packages\\google\\genai\\models.py:5380\u001b[39m, in \u001b[36mModels.generate_content_stream\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   5374\u001b[39m function_map = _extra_utils.get_function_map(parsed_config)\n\u001b[32m   5376\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m1\u001b[39m:\n\u001b[32m   5377\u001b[39m   \u001b[38;5;66;03m# First request gets a function call.\u001b[39;00m\n\u001b[32m   5378\u001b[39m   \u001b[38;5;66;03m# Then get function response parts.\u001b[39;00m\n\u001b[32m   5379\u001b[39m   \u001b[38;5;66;03m# Yield chunks only if there's no function response parts.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5380\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   5381\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfunction_map\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   5382\u001b[39m \u001b[43m      \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m_extra_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mappend_chunk_contents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[assignment]\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\vs code college\\Final project NLP\\Auto_Expert\\venv\\Lib\\site-packages\\google\\genai\\models.py:4074\u001b[39m, in \u001b[36mModels._generate_content_stream\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   4066\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[32m   4067\u001b[39m     config, \u001b[33m'\u001b[39m\u001b[33mshould_return_http_response\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4068\u001b[39m ):\n\u001b[32m   4069\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   4070\u001b[39m       \u001b[33m'\u001b[39m\u001b[33mAccessing the raw HTTP response is not supported in streaming\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   4071\u001b[39m       \u001b[33m'\u001b[39m\u001b[33m methods.\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   4072\u001b[39m   )\n\u001b[32m-> \u001b[39m\u001b[32m4074\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest_streamed\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4075\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\n\u001b[32m   4076\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   4078\u001b[39m \u001b[43m  \u001b[49m\u001b[43mresponse_dict\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4080\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvertexai\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\vs code college\\Final project NLP\\Auto_Expert\\venv\\Lib\\site-packages\\google\\genai\\_api_client.py:1405\u001b[39m, in \u001b[36mBaseApiClient.request_streamed\u001b[39m\u001b[34m(self, http_method, path, request_dict, http_options)\u001b[39m\n\u001b[32m   1394\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrequest_streamed\u001b[39m(\n\u001b[32m   1395\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1396\u001b[39m     http_method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1399\u001b[39m     http_options: Optional[HttpOptionsOrDict] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1400\u001b[39m ) -> Generator[SdkHttpResponse, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[32m   1401\u001b[39m   http_request = \u001b[38;5;28mself\u001b[39m._build_request(\n\u001b[32m   1402\u001b[39m       http_method, path, request_dict, http_options\n\u001b[32m   1403\u001b[39m   )\n\u001b[32m-> \u001b[39m\u001b[32m1405\u001b[39m   session_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1406\u001b[39m   \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m session_response.segments():\n\u001b[32m   1407\u001b[39m     chunk_dump = json.dumps(chunk)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\vs code college\\Final project NLP\\Auto_Expert\\venv\\Lib\\site-packages\\google\\genai\\_api_client.py:1222\u001b[39m, in \u001b[36mBaseApiClient._request\u001b[39m\u001b[34m(self, http_request, http_options, stream)\u001b[39m\n\u001b[32m   1220\u001b[39m     retry_kwargs = retry_args(parameter_model.retry_options)\n\u001b[32m   1221\u001b[39m     retry = tenacity.Retrying(**retry_kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1222\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_once\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retry(\u001b[38;5;28mself\u001b[39m._request_once, http_request, stream)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\vs code college\\Final project NLP\\Auto_Expert\\venv\\Lib\\site-packages\\tenacity\\__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    475\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\vs code college\\Final project NLP\\Auto_Expert\\venv\\Lib\\site-packages\\tenacity\\__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    376\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\vs code college\\Final project NLP\\Auto_Expert\\venv\\Lib\\site-packages\\tenacity\\__init__.py:420\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    418\u001b[39m retry_exc = \u001b[38;5;28mself\u001b[39m.retry_error_cls(fut)\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\vs code college\\Final project NLP\\Auto_Expert\\venv\\Lib\\site-packages\\tenacity\\__init__.py:187\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> t.NoReturn:\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\vs code college\\Final project NLP\\Auto_Expert\\venv\\Lib\\site-packages\\tenacity\\__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m         result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    482\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\vs code college\\Final project NLP\\Auto_Expert\\venv\\Lib\\site-packages\\google\\genai\\_api_client.py:1189\u001b[39m, in \u001b[36mBaseApiClient._request_once\u001b[39m\u001b[34m(self, http_request, stream)\u001b[39m\n\u001b[32m   1181\u001b[39m   httpx_request = \u001b[38;5;28mself\u001b[39m._httpx_client.build_request(\n\u001b[32m   1182\u001b[39m       method=http_request.method,\n\u001b[32m   1183\u001b[39m       url=http_request.url,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1186\u001b[39m       timeout=http_request.timeout,\n\u001b[32m   1187\u001b[39m   )\n\u001b[32m   1188\u001b[39m   response = \u001b[38;5;28mself\u001b[39m._httpx_client.send(httpx_request, stream=stream)\n\u001b[32m-> \u001b[39m\u001b[32m1189\u001b[39m   \u001b[43merrors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAPIError\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1190\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[32m   1191\u001b[39m       response.headers, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response.text]\n\u001b[32m   1192\u001b[39m   )\n\u001b[32m   1193\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\vs code college\\Final project NLP\\Auto_Expert\\venv\\Lib\\site-packages\\google\\genai\\errors.py:121\u001b[39m, in \u001b[36mAPIError.raise_for_response\u001b[39m\u001b[34m(cls, response)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    119\u001b[39m   response_json = response.body_segments[\u001b[32m0\u001b[39m].get(\u001b[33m'\u001b[39m\u001b[33merror\u001b[39m\u001b[33m'\u001b[39m, {})\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraise_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\vs code college\\Final project NLP\\Auto_Expert\\venv\\Lib\\site-packages\\google\\genai\\errors.py:146\u001b[39m, in \u001b[36mAPIError.raise_error\u001b[39m\u001b[34m(cls, status_code, response_json, response)\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Raises an appropriate APIError subclass based on the status code.\u001b[39;00m\n\u001b[32m    133\u001b[39m \n\u001b[32m    134\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    143\u001b[39m \u001b[33;03m  APIError: For other error status codes.\u001b[39;00m\n\u001b[32m    144\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m400\u001b[39m <= status_code < \u001b[32m500\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[32m500\u001b[39m <= status_code < \u001b[32m600\u001b[39m:\n\u001b[32m    148\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ServerError(status_code, response_json, response)\n",
      "\u001b[31mClientError\u001b[39m: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 46.919856701s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '46s'}]}}"
     ]
    }
   ],
   "source": [
    "auto_expert_chat(\"عايز اشتري احسن عربية في حدود مليون ونص جنيه وتكون معتمده ع انها تبقي واسعه ومريحة للعيلة\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
